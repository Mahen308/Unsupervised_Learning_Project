{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "738e1e29-c5ff-4f2e-8912-0722ffa4aacc",
   "metadata": {},
   "source": [
    "***Setup and imports***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec98d6d8-e6d5-4598-b89a-0319fff2a1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Python & scientific stack\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Dict, List\n",
    "\n",
    "# Sparse + ML utilities\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ec8fd1-a4e6-41d3-8e3f-cf80ac710dd7",
   "metadata": {},
   "source": [
    "***Configuration & Data Loading***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "077842bc-3983-419a-8861-24aec68d8877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (5703555, 3), Test size: (633686, 2)\n",
      "Rating range: [1.0, 10.0], Global mean=7.809\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "BASE_DIR = \"Data\"\n",
    "\n",
    "PATH_ANIME = os.path.join(BASE_DIR, \"anime.csv\")\n",
    "PATH_TRAIN = os.path.join(BASE_DIR, \"train.csv\")\n",
    "PATH_TEST  = os.path.join(BASE_DIR, \"test.csv\")\n",
    "\n",
    "USER, ITEM, RATE = \"user_id\", \"anime_id\", \"rating\"\n",
    "\n",
    "# Speed mode toggle\n",
    "USE_SMALL = False\n",
    "USER_CAP  = 2000\n",
    "ITEM_CAP  = 3000\n",
    "\n",
    "# Load tables\n",
    "anime_raw = pd.read_csv(PATH_ANIME)\n",
    "train_raw = pd.read_csv(PATH_TRAIN)\n",
    "test_raw  = pd.read_csv(PATH_TEST)\n",
    "\n",
    "# Clean invalid ratings\n",
    "train_raw = train_raw[pd.to_numeric(train_raw[RATE], errors=\"coerce\").notnull()].copy()\n",
    "train_raw[RATE] = train_raw[RATE].astype(float)\n",
    "train_raw = train_raw[train_raw[RATE] >= 0].copy()\n",
    "\n",
    "# Stats\n",
    "rmin, rmax = float(train_raw[RATE].min()), float(train_raw[RATE].max())\n",
    "gmean = float(train_raw[RATE].mean())\n",
    "\n",
    "print(f\"Train size: {train_raw.shape}, Test size: {test_raw.shape}\")\n",
    "print(f\"Rating range: [{rmin}, {rmax}], Global mean={gmean:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd3f3d9-48fe-4908-8d38-53a5e0988c4d",
   "metadata": {},
   "source": [
    "***Build Lightweight Content Text (Metadata)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a9307ad-74f2-42f3-a3e1-b0a829970378",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = [c for c in [\"genre\", \"type\", \"name\", \"episodes\"] if c in anime_raw.columns]\n",
    "\n",
    "anime_raw[\"meta_text\"] = (\n",
    "    anime_raw[text_cols].astype(str).agg(\" \".join, axis=1)\n",
    ")\n",
    "\n",
    "# Keep only item IDs present in training data\n",
    "all_item_ids = sorted(train_raw[ITEM].unique())\n",
    "anime_info = pd.DataFrame({ITEM: all_item_ids}).merge(\n",
    "    anime_raw[[ITEM, \"meta_text\"]], on=ITEM, how=\"left\"\n",
    ").fillna({\"meta_text\": \"\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8577a26c-680e-4c87-9aa3-a8764d1c3b1c",
   "metadata": {},
   "source": [
    "***Integer Mappings & Sparse Matrix***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6696ab04-37cd-4c64-9f0c-c657fc6963f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users=69481, Items=9838\n"
     ]
    }
   ],
   "source": [
    "# ID → index mappings\n",
    "u_index = {u: i for i, u in enumerate(sorted(train_raw[USER].unique()))}\n",
    "i_index = {a: j for j, a in enumerate(all_item_ids)}\n",
    "\n",
    "nU, nI = len(u_index), len(i_index)\n",
    "print(f\"Users={nU}, Items={nI}\")\n",
    "\n",
    "# Sparse CSR rating matrix\n",
    "r = train_raw\n",
    "row = r[USER].map(u_index).values\n",
    "col = r[ITEM].map(i_index).values\n",
    "val = r[RATE].values\n",
    "\n",
    "Rmat = sparse.coo_matrix((val, (row, col)), shape=(nU, nI)).tocsr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45475b8-ed88-43c0-88f0-e95e6b01f7c1",
   "metadata": {},
   "source": [
    "***Per-User & Per-Item Means***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05dc4923-e232-4973-937e-2fd98cd96165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csr_axis_mean(mat: sparse.csr_matrix, axis=1):\n",
    "    # axis=1 → per-row; axis=0 → per-column\n",
    "    if axis == 0:\n",
    "        return csr_axis_mean(mat.T, axis=1)\n",
    "\n",
    "    means = np.zeros(mat.shape[0], dtype=float)\n",
    "    for r in range(mat.shape[0]):\n",
    "        s, e = mat.indptr[r], mat.indptr[r+1]\n",
    "        means[r] = mat.data[s:e].mean() if e > s else gmean\n",
    "    return means\n",
    "\n",
    "u_mean = csr_axis_mean(Rmat, axis=1)\n",
    "i_mean = csr_axis_mean(Rmat, axis=0)\n",
    "\n",
    "# Quick lookup dict of items per user\n",
    "user_r: List[Dict[int, float]] = [dict() for _ in range(nU)]\n",
    "\n",
    "for u in range(nU):\n",
    "    s, e = Rmat.indptr[u], Rmat.indptr[u+1]\n",
    "    rated_items = Rmat.indices[s:e]\n",
    "    rated_vals  = Rmat.data[s:e]\n",
    "    user_r[u]   = {int(i): float(r) for i, r in zip(rated_items, rated_vals)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da10669-7301-4fa3-a6ec-e969bef0f86c",
   "metadata": {},
   "source": [
    "***Similarity Neighbors (CF + Content)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7474c78c-fa3b-4406-9384-745ce0532404",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_NEIGH = 30 if not USE_SMALL else 25\n",
    "\n",
    "# ---- CF neighbor model (item-item) ----\n",
    "item_knn = NearestNeighbors(\n",
    "    metric=\"cosine\", algorithm=\"brute\",\n",
    "    n_neighbors=min(K_NEIGH+1, nI)\n",
    ").fit(Rmat.T)\n",
    "\n",
    "cf_d, cf_i = item_knn.kneighbors(Rmat.T)\n",
    "cf_s = 1.0 - cf_d\n",
    "cf_i, cf_s = cf_i[:, 1:], cf_s[:, 1:]    # remove self-neighbor\n",
    "\n",
    "# ---- Content-based neighbors ----\n",
    "tfidf_vec = TfidfVectorizer(\n",
    "    max_features=40000 if not USE_SMALL else 20000,\n",
    "    min_df=3, ngram_range=(1,2)\n",
    ")\n",
    "content_matrix = tfidf_vec.fit_transform(anime_info[\"meta_text\"])\n",
    "\n",
    "cb_knn = NearestNeighbors(\n",
    "    metric=\"cosine\", algorithm=\"brute\",\n",
    "    n_neighbors=min(K_NEIGH+1, nI)\n",
    ").fit(content_matrix)\n",
    "\n",
    "cb_d, cb_i = cb_knn.kneighbors(content_matrix)\n",
    "cb_s = 1.0 - cb_d\n",
    "cb_i, cb_s = cb_i[:, 1:], cb_s[:, 1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b105c18-7727-49b6-9694-738f677892e6",
   "metadata": {},
   "source": [
    "***Prediction Functions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "926c8107-f448-44b4-9622-1eab0c104a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_neighbor_mean(\n",
    "    uid: int, iid: int,\n",
    "    neigh_idx: np.ndarray,\n",
    "    neigh_sim: np.ndarray\n",
    ") -> float:\n",
    "    \"\"\"Predict rating using weighted average on similar items.\"\"\"\n",
    "    total, weight = 0.0, 0.0\n",
    "    rated = user_r[uid]\n",
    "\n",
    "    for nb, s in zip(neigh_idx[iid], neigh_sim[iid]):\n",
    "        r = rated.get(int(nb))\n",
    "        if r is None:\n",
    "            continue\n",
    "        total += s * r\n",
    "        weight += abs(s)\n",
    "\n",
    "    if weight > 0:\n",
    "        return total / weight\n",
    "\n",
    "    return 0.5 * u_mean[uid] + 0.5 * i_mean[iid]\n",
    "\n",
    "\n",
    "def hybrid_predict(uid: int, iid: int, alpha: float) -> float:\n",
    "    p_cf = weighted_neighbor_mean(uid, iid, cf_i, cf_s)\n",
    "    p_cb = weighted_neighbor_mean(uid, iid, cb_i, cb_s)\n",
    "    return alpha * p_cf + (1 - alpha) * p_cb\n",
    "\n",
    "\n",
    "def predict(uid, iid, alpha):\n",
    "    u = u_index.get(uid)\n",
    "    i = i_index.get(iid)\n",
    "\n",
    "    if u is None and i is None:\n",
    "        return gmean\n",
    "    if u is None:\n",
    "        return i_mean[i]\n",
    "    if i is None:\n",
    "        return u_mean[u]\n",
    "\n",
    "    p = hybrid_predict(u, i, alpha)\n",
    "    return float(np.clip(p, rmin, rmax))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112eb22f-c049-41bf-9d9a-0f4c75043fa8",
   "metadata": {},
   "source": [
    "***Tune α on Validation Set***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3612d00-8f70-4898-9fe8-2fbfcbb75293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal α = 0.70 | RMSE=1.1931\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1.193146</td>\n",
       "      <td>0.871180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.194525</td>\n",
       "      <td>0.871917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1.198820</td>\n",
       "      <td>0.874706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.202931</td>\n",
       "      <td>0.877067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.211448</td>\n",
       "      <td>0.882437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.218221</td>\n",
       "      <td>0.886259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>1.230815</td>\n",
       "      <td>0.894289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1.256610</td>\n",
       "      <td>0.909699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.288446</td>\n",
       "      <td>0.928118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1.325890</td>\n",
       "      <td>0.948891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.368480</td>\n",
       "      <td>0.971492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha      rmse       mae\n",
       "7     0.7  1.193146  0.871180\n",
       "8     0.8  1.194525  0.871917\n",
       "6     0.6  1.198820  0.874706\n",
       "9     0.9  1.202931  0.877067\n",
       "5     0.5  1.211448  0.882437\n",
       "10    1.0  1.218221  0.886259\n",
       "4     0.4  1.230815  0.894289\n",
       "3     0.3  1.256610  0.909699\n",
       "2     0.2  1.288446  0.928118\n",
       "1     0.1  1.325890  0.948891\n",
       "0     0.0  1.368480  0.971492"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reliable RMSE\n",
    "def RMSE(true, pred):\n",
    "    try:\n",
    "        return mean_squared_error(true, pred, squared=False)\n",
    "    except:\n",
    "        return np.sqrt(mean_squared_error(true, pred))\n",
    "\n",
    "# 90/10 split\n",
    "train_small, valid = train_test_split(train_raw, test_size=0.10, random_state=13)\n",
    "\n",
    "# Downsample for speed\n",
    "valid = valid.sample(n=min(50000, len(valid)), random_state=13).reset_index(drop=True)\n",
    "\n",
    "def evaluate(df, alpha):\n",
    "    true = df[RATE].astype(float).values\n",
    "    pred = [predict(u, a, alpha) for u, a in df[[USER, ITEM]].itertuples(index=False)]\n",
    "\n",
    "    return RMSE(true, pred), mean_absolute_error(true, pred)\n",
    "\n",
    "alphas = np.linspace(0, 1, 11)\n",
    "results = []\n",
    "\n",
    "best_alpha = None\n",
    "best_rmse = float(\"inf\")\n",
    "\n",
    "for a in alphas:\n",
    "    rm, ma = evaluate(valid, a)\n",
    "    results.append((a, rm, ma))\n",
    "\n",
    "    if rm < best_rmse:\n",
    "        best_rmse = rm\n",
    "        best_alpha = a\n",
    "\n",
    "print(f\"Optimal α = {best_alpha:.2f} | RMSE={best_rmse:.4f}\")\n",
    "pd.DataFrame(results, columns=[\"alpha\", \"rmse\", \"mae\"]).sort_values(\"rmse\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6f1575-7142-4b6d-8453-9efb3aa30d7a",
   "metadata": {},
   "source": [
    "***Predict for Test Set***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a9006c9-6aeb-4697-a7fb-d4d06660ad84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: Data\\predictions_custom.csv\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "CHUNK = 200_000\n",
    "\n",
    "for s in range(0, len(test_raw), CHUNK):\n",
    "    block = test_raw.iloc[s:s+CHUNK]\n",
    "    block_pred = [\n",
    "        predict(u, i, best_alpha)\n",
    "        for u, i in block[[USER, ITEM]].itertuples(index=False)\n",
    "    ]\n",
    "    predictions.extend(block_pred)\n",
    "\n",
    "submission = test_raw.copy()\n",
    "submission[RATE] = predictions[:len(test_raw)]\n",
    "\n",
    "OUT_CSV = os.path.join(BASE_DIR, \"predictions_custom.csv\")\n",
    "submission.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(\"Saved:\", OUT_CSV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182a5f92-bc3e-443a-b71d-4ada70d0ab22",
   "metadata": {},
   "source": [
    "***Save Model Artifact***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "459addb0-ed35-4530-8923-556c2f44519e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifact saved → Data\\hybrid_recommender_custom.json\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def to_py(x):\n",
    "    \"\"\"\n",
    "    Convert numpy types → Python native types so JSON can serialize them.\n",
    "    \"\"\"\n",
    "    if isinstance(x, (np.integer, np.int64, np.int32)):\n",
    "        return int(x)\n",
    "    if isinstance(x, (np.floating, np.float32, np.float64)):\n",
    "        return float(x)\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return x.tolist()\n",
    "    return x\n",
    "\n",
    "def pack_csr_safe(csr):\n",
    "    return {\n",
    "        \"data\":   to_py(csr.data),\n",
    "        \"indices\": to_py(csr.indices),\n",
    "        \"indptr\":  to_py(csr.indptr),\n",
    "        \"shape\":   [int(csr.shape[0]), int(csr.shape[1])]\n",
    "    }\n",
    "\n",
    "artifact = {\n",
    "    \"global_mean\": float(gmean),\n",
    "    \"rating_min\":  float(rmin),\n",
    "    \"rating_max\":  float(rmax),\n",
    "    \"best_alpha\":  float(best_alpha),\n",
    "    \"user_ids\":    [int(x) for x in u_index.keys()],\n",
    "    \"item_ids\":    [int(x) for x in i_index.keys()],\n",
    "    \"user_mean\":   [float(v) for v in u_mean.tolist()],\n",
    "    \"item_mean\":   [float(v) for v in i_mean.tolist()],\n",
    "    \"R_matrix\":    pack_csr_safe(Rmat),\n",
    "}\n",
    "\n",
    "ART_PATH = os.path.join(BASE_DIR, \"hybrid_recommender_custom.json\")\n",
    "\n",
    "with open(ART_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(artifact, f)\n",
    "\n",
    "print(\"Artifact saved →\", ART_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1310efeb-8e80-4df9-bb6f-fe8a969d5124",
   "metadata": {},
   "source": [
    "***Streamlit***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1764cef8-5466-43bf-a331-d37ede10f199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Encoder for numpy types\n",
    "def np_encoder(obj):\n",
    "    if isinstance(obj, np.generic):\n",
    "        return obj.item()  # Convert to Python native type\n",
    "    raise TypeError(f\"Object of type {type(obj)} is not JSON serializable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e090f555-005c-48a8-859b-f369903bd56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ART_PATH = os.path.join(DATA_DIR, \"hybrid_recommender_custom.json\")\n",
    "with open(ART_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(artifact, f, default=np_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bbb1a27-f17f-47f1-a9c6-273375b27896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo artifact created at: C:\\Users\\Admin\\Documents\\GitHub\\Unsupervised_Learning_Project\\hybrid_recommender_custom.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "DATA_DIR = r\"C:\\Users\\Admin\\Documents\\GitHub\\Unsupervised_Learning_Project\"\n",
    "ART_PATH = os.path.join(DATA_DIR, \"hybrid_recommender_custom.json\")\n",
    "\n",
    "artifact_demo = {\n",
    "    \"global_mean\": 5.0,\n",
    "    \"rating_min\": 1.0,\n",
    "    \"rating_max\": 10.0,\n",
    "    \"best_alpha\": 0.7,\n",
    "    \"user_ids\": [1, 2, 3],\n",
    "    \"item_ids\": [101, 102, 103],\n",
    "    \"user_mean\": [5.0, 6.0, 7.0],\n",
    "    \"item_mean\": [5.5, 6.5, 7.5],\n",
    "    \"R_csr\": {\n",
    "        \"data\": [5, 6, 7],\n",
    "        \"indices\": [0, 1, 2],\n",
    "        \"indptr\": [0, 1, 2, 3],\n",
    "        \"shape\": [3, 3]\n",
    "    }\n",
    "}\n",
    "\n",
    "def np_encoder(obj):\n",
    "    if isinstance(obj, np.generic):\n",
    "        return obj.item()\n",
    "    raise TypeError\n",
    "\n",
    "with open(ART_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(artifact_demo, f, default=np_encoder)\n",
    "\n",
    "print(\"Demo artifact created at:\", ART_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddcd2a20-b6c6-4a99-a7ee-df7e40533b77",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'art' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(art.keys())\n",
      "\u001b[31mNameError\u001b[39m: name 'art' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba634c6-a9f6-475f-913b-4cd8e86aaab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
